{"cells":[{"cell_type":"markdown","metadata":{"id":"pBA5tDWp69GM"},"source":["# 소개\n","슈팅스타! 팀 프로젝트를 colab환경에서 간단히 테스트 해볼 수 있는 ipynb 파일 입니다.\n","___\n","\n","## 사전 준비\n","- data 폴더엔 질문-문서.jsonl 파일과, 학습된 모델.pth 파일을 넣어 주시면 됩니다.\n","- vectordb 폴더는 자동생성되고, 만약 있는걸 사용하신다면 하단 main함수에 알맞은 경로를 넣어서 불러와서 사용하면 됩니다.\n","- ipynb파일 경로를 %cd를 통해 지정해주고 (예시) `%cd '/content/drive/MyDrive/Colab Notebooks/yeardream/shootingstar_test'`\n","    - 해당 폴더에 .env를 만들고 안에 'OPENAI_API_KEY'='sk-...'\n","- 최하단에 main.py에 들어가는 인자를 알맞게 수정\n","- 특히 is_first가 True일시 문서 임베딩을 처음부터 다시 하는데다가, 덮어쓰는게 아니라 추가로 넣어버리기 때문에 해당모델을 하는게 아니라면 True로 설정하시면 안됩니다.\n","    - 이 값을 True로 하는 경우 = 모델을 바꾸거나, workspace를 변경했을때 True\n","___\n","\n","\n","## main.py 부분 사용법\n","- 문서데이터를 처음부터 임베딩 하는게 아니라면 굳이 gpu런타임을 할 필요 없습니다.\n","- 모두 실행후 최하단에 input 입력창이 생기면 질문을 넣고 답변을 받을 수 있습니다.\n","___\n","## eval.py 부분 사용법\n","- main.py 이전셀을 실행후 실행하면 됩니다\n","- main.py를 돌리고 있는 중이라면 'exit'를 입력해 빠져나오거나, 직접 중지해주고 실행해주세요\n","- model_paths = [\"data/museum_5epochs.pth\", \"\"]\n","    - 평가할 모델의 경로를 순서대로 적어줍니다 (workspace와 순서가 같아야함)\n","    - \"\"은 klue/bert-base 모델을 적용합니다 (dpr X)\n","- workspaces = [\"vectordb/museum_5epochs\", \"vectordb/bert-base\"]\n","    - 해당 모델로 임베딩한 index.bin이 있는 경로를 지정해줍니다.\n","    - 여기서 '/' 다음 부분이 csv파일에 모델이름으로 기록되게 됩니다.\n","\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18528,"status":"ok","timestamp":1702426312311,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"Gp32d7OeN3fc","outputId":"2b3a7327-3a11-4038-bb1e-d462aaae2d06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":502,"status":"ok","timestamp":1702426312810,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"tK-CipyFpvpC","outputId":"ed7f635b-1025-4863-9b78-1f0360984b95"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/슈팅스타/shootingstar_test\n"]}],"source":["# 자신의 폴더 위치에 맞게 아래 경로 변경해야 함\n","%cd '/content/drive/MyDrive/Colab Notebooks/슈팅스타/shootingstar_test'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83346,"status":"ok","timestamp":1702426396152,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"4ff7HqPHqq35","outputId":"4e1dc937-c5a2-482a-8be6-acd2cf18774d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting python-dotenv\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Collecting docarray\n","  Downloading docarray-0.39.1-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.4/265.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting vectordb\n","  Downloading vectordb-0.0.20.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting langchain\n","  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openai\n","  Downloading openai-1.3.8-py3-none-any.whl (221 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.5/221.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.23.5)\n","Collecting orjson>=3.8.2 (from docarray)\n","  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from docarray) (1.10.13)\n","Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (13.7.0)\n","Collecting types-requests>=2.28.11.6 (from docarray)\n","  Downloading types_requests-2.31.0.10-py3-none-any.whl (14 kB)\n","Collecting typing-inspect>=0.8.0 (from docarray)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting jina>=3.20.0 (from vectordb)\n","  Downloading jina-3.23.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n","  Downloading langchain_community-0.0.2-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n","  Downloading langchain_core-0.1.0-py3-none-any.whl (189 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n","  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hnswlib>=0.7.0 (from docarray)\n","  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from docarray) (3.20.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets (from jina>=3.20.0->vectordb)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio-health-checking<1.48.1,>=1.46.0 (from jina>=3.20.0->vectordb)\n","  Downloading grpcio_health_checking-1.47.5-py3-none-any.whl (8.7 kB)\n","Collecting jina-hubble-sdk>=0.30.4 (from jina>=3.20.0->vectordb)\n","  Downloading jina_hubble_sdk-0.39.0-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.3/68.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (23.2)\n","Collecting urllib3<2.0.0,>=1.25.9 (from jina>=3.20.0->vectordb)\n","  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pathspec (from jina>=3.20.0->vectordb)\n","  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.13.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.21.0-py3-none-any.whl (18 kB)\n","Collecting grpcio-reflection<1.48.1,>=1.46.0 (from jina>=3.20.0->vectordb)\n","  Downloading grpcio_reflection-1.47.5-py3-none-any.whl (11 kB)\n","Collecting jcloud>=0.0.35 (from jina>=3.20.0->vectordb)\n","  Downloading jcloud-0.3.tar.gz (39 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting opentelemetry-instrumentation-grpc>=0.35b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_grpc-0.42b0-py3-none-any.whl (26 kB)\n","Collecting opentelemetry-api>=1.12.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_api-1.21.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.76.0 (from jina>=3.20.0->vectordb)\n","  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-multipart (from jina>=3.20.0->vectordb)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-prometheus>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_prometheus-0.42b0-py3-none-any.whl (10 kB)\n","Collecting aiofiles (from jina>=3.20.0->vectordb)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Collecting docker (from jina>=3.20.0->vectordb)\n","  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]<=0.23.1 (from jina>=3.20.0->vectordb)\n","  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: prometheus-client>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.19.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (3.13.1)\n","Collecting opentelemetry-instrumentation-fastapi>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.42b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-sdk<1.20.0,>=1.14.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_sdk-1.19.0-py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting grpcio<1.48.1,>=1.46.0 (from jina>=3.20.0->vectordb)\n","  Downloading grpcio-1.47.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp>=1.12.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp-1.21.0-py3-none-any.whl (7.0 kB)\n","Collecting opentelemetry-instrumentation-aiohttp-client>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_aiohttp_client-0.42b0-py3-none-any.whl (11 kB)\n","Collecting uvloop (from jina>=3.20.0->vectordb)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray) (2.16.1)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n","INFO: pip is looking at multiple versions of types-requests to determine which version is compatible with other requirements. This could take a while.\n","Collecting types-requests>=2.28.11.6 (from docarray)\n","  Downloading types_requests-2.31.0.9-py3-none-any.whl (14 kB)\n","  Downloading types_requests-2.31.0.8-py3-none-any.whl (14 kB)\n","  Downloading types_requests-2.31.0.7-py3-none-any.whl (14 kB)\n","  Downloading types_requests-2.31.0.6-py3-none-any.whl (14 kB)\n","Collecting types-urllib3 (from types-requests>=2.28.11.6->docarray)\n","  Downloading types_urllib3-1.26.25.14-py3-none-any.whl (15 kB)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->docarray)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.76.0->jina>=3.20.0->vectordb)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions<5,>=4.5 (from openai)\n","  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from grpcio<1.48.1,>=1.46.0->jina>=3.20.0->vectordb) (1.16.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from jcloud>=0.0.35->jina>=3.20.0->vectordb) (2.8.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (7.0.0)\n","Collecting python-jose (from jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb)\n","  Downloading python_jose-3.3.0-py2.py3-none-any.whl (33 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray) (0.1.2)\n","Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.12.0->jina>=3.20.0->vectordb)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting importlib-metadata (from jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb)\n","  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.21.0 (from opentelemetry-exporter-otlp>=1.12.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.21.0-py3-none-any.whl (16 kB)\n","Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb) (1.61.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.21.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.21.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_proto-1.21.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-exporter-otlp>=1.12.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp-1.20.0-py3-none-any.whl (7.0 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.13.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.20.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.20.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.20.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_proto-1.20.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.13.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.19.0-py3-none-any.whl (18 kB)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.19.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.19.0-py3-none-any.whl (17 kB)\n","Collecting opentelemetry-proto==1.19.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_proto-1.19.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-api>=1.12.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_api-1.19.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting opentelemetry-semantic-conventions==0.40b0 (from opentelemetry-sdk<1.20.0,>=1.14.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_semantic_conventions-0.40b0-py3-none-any.whl (26 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.20.0 (from opentelemetry-exporter-otlp>=1.12.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.20.0-py3-none-any.whl (16 kB)\n","Collecting opentelemetry-exporter-otlp>=1.12.0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp-1.19.0-py3-none-any.whl (7.0 kB)\n","Collecting opentelemetry-exporter-otlp-proto-http==1.19.0 (from opentelemetry-exporter-otlp>=1.12.0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_otlp_proto_http-1.19.0-py3-none-any.whl (17 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-exporter-prometheus to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-exporter-prometheus>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_exporter_prometheus-0.41b0-py3-none-any.whl (10 kB)\n","Collecting opentelemetry-instrumentation==0.42b0 (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation-0.42b0-py3-none-any.whl (25 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-instrumentation-aiohttp-client to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-instrumentation-aiohttp-client>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_aiohttp_client-0.41b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-instrumentation==0.41b0 (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation-0.41b0-py3-none-any.whl (25 kB)\n","Collecting opentelemetry-instrumentation-aiohttp-client>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_aiohttp_client-0.40b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-instrumentation==0.40b0 (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation-0.40b0-py3-none-any.whl (25 kB)\n","Collecting opentelemetry-util-http==0.40b0 (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_util_http-0.40b0-py3-none-any.whl (6.7 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (1.14.1)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.40b0->opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (67.7.2)\n","Collecting opentelemetry-instrumentation-asgi==0.42b0 (from opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_asgi-0.42b0-py3-none-any.whl (13 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-instrumentation-fastapi to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-instrumentation-fastapi>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.41b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.41b0 (from opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_asgi-0.41b0-py3-none-any.whl (13 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.33b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.40b0-py3-none-any.whl (11 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.40b0 (from opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_asgi-0.40b0-py3-none-any.whl (13 kB)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.40b0->opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb)\n","  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n","INFO: pip is looking at multiple versions of opentelemetry-instrumentation-grpc to determine which version is compatible with other requirements. This could take a while.\n","Collecting opentelemetry-instrumentation-grpc>=0.35b0 (from jina>=3.20.0->vectordb)\n","  Downloading opentelemetry_instrumentation_grpc-0.41b0-py3-none-any.whl (26 kB)\n","  Downloading opentelemetry_instrumentation_grpc-0.40b0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb) (8.1.7)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (3.17.0)\n","Collecting ecdsa!=0.15 (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb)\n","  Downloading ecdsa-0.18.0-py2.py3-none-any.whl (142 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.9/142.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: rsa in /usr/local/lib/python3.10/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (4.9)\n","Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (0.5.1)\n","Building wheels for collected packages: vectordb, hnswlib, jcloud\n","  Building wheel for vectordb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vectordb: filename=vectordb-0.0.20-py3-none-any.whl size=27406 sha256=8501473b95c09b5d041f406ee520afc790dbb6ab8986afa938df9097fbd926b7\n","  Stored in directory: /root/.cache/pip/wheels/cf/0a/c3/bcc76927220074a579446d8bd2253e20c75686c70fc61b8a88\n","  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2287617 sha256=43b51e6318464088f2ea1159cef7e1ca8b7ccb7718614752c74c59342efaa0a8\n","  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n","  Building wheel for jcloud (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jcloud: filename=jcloud-0.3-py3-none-any.whl size=46469 sha256=5d1a8f6b968bd0dc32b9ba1d5c484710dc1e87f21c7abfb9c3d5f826de32910e\n","  Stored in directory: /root/.cache/pip/wheels/4d/66/bc/e0fe53791a7205fbb7ce1f6e2e1187afdf1ec8f1fce2e8c8d4\n","Successfully built vectordb hnswlib jcloud\n","Installing collected packages: types-urllib3, websockets, uvloop, urllib3, typing-extensions, types-requests, python-multipart, python-dotenv, pathspec, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, mypy-extensions, marshmallow, jsonpointer, importlib-metadata, httptools, hnswlib, h11, grpcio, ecdsa, deprecated, backoff, aiofiles, watchfiles, uvicorn, typing-inspect, starlette, python-jose, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, httpcore, grpcio-reflection, grpcio-health-checking, asgiref, opentelemetry-sdk, opentelemetry-instrumentation, langsmith, httpx, fastapi, docker, docarray, dataclasses-json, opentelemetry-instrumentation-grpc, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-aiohttp-client, opentelemetry-exporter-prometheus, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openai, langchain-core, jina-hubble-sdk, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp, langchain-community, jcloud, langchain, jina, vectordb\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 7.0.0\n","    Uninstalling importlib-metadata-7.0.0:\n","      Successfully uninstalled importlib-metadata-7.0.0\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.59.3\n","    Uninstalling grpcio-1.59.3:\n","      Successfully uninstalled grpcio-1.59.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.47.5 which is incompatible.\n","tensorboard 2.14.1 requires grpcio>=1.48.2, but you have grpcio 1.47.5 which is incompatible.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 asgiref-3.7.2 backoff-2.2.1 dataclasses-json-0.6.3 deprecated-1.2.14 docarray-0.39.1 docker-7.0.0 ecdsa-0.18.0 fastapi-0.105.0 grpcio-1.47.5 grpcio-health-checking-1.47.5 grpcio-reflection-1.47.5 h11-0.14.0 hnswlib-0.8.0 httpcore-1.0.2 httptools-0.6.1 httpx-0.25.2 importlib-metadata-6.11.0 jcloud-0.3 jina-3.23.1 jina-hubble-sdk-0.39.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.2 langchain-core-0.1.0 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.8 opentelemetry-api-1.19.0 opentelemetry-exporter-otlp-1.19.0 opentelemetry-exporter-otlp-proto-common-1.19.0 opentelemetry-exporter-otlp-proto-grpc-1.19.0 opentelemetry-exporter-otlp-proto-http-1.19.0 opentelemetry-exporter-prometheus-0.41b0 opentelemetry-instrumentation-0.40b0 opentelemetry-instrumentation-aiohttp-client-0.40b0 opentelemetry-instrumentation-asgi-0.40b0 opentelemetry-instrumentation-fastapi-0.40b0 opentelemetry-instrumentation-grpc-0.40b0 opentelemetry-proto-1.19.0 opentelemetry-sdk-1.19.0 opentelemetry-semantic-conventions-0.40b0 opentelemetry-util-http-0.40b0 orjson-3.9.10 pathspec-0.12.1 python-dotenv-1.0.0 python-jose-3.3.0 python-multipart-0.0.6 starlette-0.27.0 types-requests-2.31.0.6 types-urllib3-1.26.25.14 typing-extensions-4.9.0 typing-inspect-0.9.0 urllib3-1.26.18 uvicorn-0.23.1 uvloop-0.19.0 vectordb-0.0.20 watchfiles-0.21.0 websockets-12.0\n"]}],"source":["!pip install python-dotenv docarray vectordb langchain openai\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":15083,"status":"ok","timestamp":1702426411224,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"NyZZx01RhR1b"},"outputs":[],"source":["import os\n","import json\n","from dotenv import load_dotenv\n","from typing import Optional, Literal\n","from tqdm.auto import tqdm\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from docarray import BaseDoc, DocList\n","from docarray.typing import NdArray\n","from vectordb import InMemoryExactNNVectorDB\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel, BertModel\n","from kobert_tokenizer import KoBERTTokenizer\n","\n","\n","from langchain.chat_models import ChatOpenAI\n","from langchain.schema import HumanMessage, SystemMessage, AIMessage, ChatMessage\n","from langchain.callbacks.base import BaseCallbackHandler\n","from langchain.callbacks import get_openai_callback\n","\n","import textwrap\n","\n","\n","load_dotenv()\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n","OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1702426411224,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"shwEO7YKhOJ6"},"outputs":[],"source":["# llmvdb/doc.py\n","class ToyDoc(BaseDoc):\n","    text: str = \"\"\n","    context_embedding: Optional[NdArray[768]]\n","    question: str = \"\"\n","    question_embedding: Optional[NdArray[768]]\n","    tit_id: str = \"\"\n","    ctx_id: str = \"\"\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1702426411224,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"Ym4uW51piCGq"},"outputs":[],"source":["# llmvdb/customdataset.py\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, file_path, max_lines=None):\n","        self.documents_data = []\n","        seen_ctx_ids = set()\n","        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","            for line in file:\n","                data = json.loads(line)\n","                ctx_id = data.get(\"ctx_id\")\n","\n","                if ctx_id not in seen_ctx_ids:\n","                    self.documents_data.append(data)\n","                    seen_ctx_ids.add(ctx_id)\n","\n","                if max_lines and len(self.documents_data) >= max_lines:\n","                    break\n","\n","    def __len__(self):\n","        return len(self.documents_data)\n","\n","    def __getitem__(self, idx):\n","        data = self.documents_data[idx]\n","        text = f'{data.get(\"title\", \"\")}\\n{data.get(\"context\", \"\")}{data.get(\"description\",\"\")}'\n","        return {\n","            \"text\": text,\n","            \"question\": data.get(\"question\", \"\"),\n","            \"ctx_id\": data.get(\"ctx_id\"),\n","            \"tit_id\": data.get(\"tit_id\"),\n","        }\n","\n","\n","class EvalCustomDataset(CustomDataset):\n","    def __init__(self, file_path):\n","        self.documents_data = []\n","        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n","            for line in file:\n","                data = json.loads(line)\n","                self.documents_data.append(data)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1702426411224,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"UBKV4aPgiGUb"},"outputs":[],"source":["# llmvdb/embedding.py\n","\n","class HuggingFaceEmbedding:\n","    def __init__(self, model_name: str = \"klue/bert-base\", use_gpu: bool = True):\n","        self.device = torch.device(\n","            \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n","        )\n","        if model_name == \"skt/kobert-base-v1\":\n","            self.tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n","            self.model = BertModel.from_pretrained(\"skt/kobert-base-v1\").to(self.device)\n","            pass\n","        else:\n","            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","            self.model = AutoModel.from_pretrained(model_name).to(self.device)\n","        print(f\"====={self.device}를 사용해서 임베딩합니다=====\")\n","\n","    def get_embedding(self, prompt):\n","        if isinstance(prompt, str):\n","            prompt = [prompt]\n","\n","        inputs = self.tokenizer(\n","            prompt, padding=True, truncation=True, return_tensors=\"pt\", max_length=512\n","        )\n","        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n","        with torch.no_grad():\n","            model_output = self.model(**inputs)\n","        sentence_embeddings = self.mean_pooling(model_output, inputs[\"attention_mask\"])\n","        return sentence_embeddings.cpu()\n","\n","    @staticmethod\n","    def mean_pooling(model_output, attention_mask):\n","        token_embeddings = model_output[0]\n","        input_mask_expanded = (\n","            attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","        )\n","        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n","            input_mask_expanded.sum(1), min=1e-9\n","        )\n","\n","\n","class DPRTextEmbedding(HuggingFaceEmbedding):\n","    def __init__(\n","        self,\n","        mode: Literal[\"passage\", \"question\"],\n","        model_path: str = \"./data/kmrc_mrc.pth\",\n","        model_name: str = \"klue/bert-base\",\n","    ):\n","        if mode not in [\"passage\", \"question\"]:\n","            raise ValueError(\"Mode must be 'passage' or 'question'\")\n","        super().__init__(model_name)\n","        self.mode = mode\n","        self.model_dict = {}\n","        self.load_model = torch.load(model_path, map_location=torch.device(\"cpu\"))\n","        for key in self.load_model.keys():\n","            if key.startswith(f\"module.{self.mode}_encoder.\"):\n","                self.model_dict[\n","                    key.replace(f\"module.{self.mode}_encoder.\", \"\")\n","                ] = self.load_model[key]\n","        self.model.load_state_dict(self.model_dict, strict=True)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1702426411224,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"xrP86uBGiVFr"},"outputs":[],"source":["# llmvdb/langchain.py\n","\n","class LangChain:\n","    def __init__(self, api_token=None, instruction=None, callbacks=None, verbose=False):\n","        self.api_token = api_token or os.getenv(\"OPENAI_API_KEY\") or None\n","        if self.api_token is None:\n","            raise ValueError(\"Open API 키가 필요합니다\")\n","        self.instruction = instruction\n","        self.callbacks = callbacks\n","        self.verbose = verbose\n","        self.streaming = False if self.callbacks is None else True\n","        self.model = \"gpt-3.5-turbo-1106\"\n","        self.llm = ChatOpenAI(\n","            model=self.model,\n","            temperature=0.3,\n","            streaming=self.streaming,\n","            callbacks=self.callbacks,\n","        )\n","        self.system_message = f\"{self.instruction}\\n 주어지는 참고용 문서를 바탕으로 사용자의 질문에 답변해줘. 사용자의 질문을 자세히 분석해서 문서를 참고해 질문의 답변을 해줘\\n 만약 문서에서 질문에 대한 답변을 찾을 수 없으면 반드시 '참고할 수 있는 문서가 없습니다.' 라고 말하고, 이후에 너가 아는 정보를 말해줘\"\n","        self.history_memory = []\n","        self.initial_history_memory = [SystemMessage(content=self.system_message)]\n","\n","    def append_limit_length(self, human_message, ai_message):\n","        new_pair_len = len(human_message.content) + len(ai_message.content)\n","\n","        while (\n","            sum(len(msg.content) for msg in self.history_memory) + new_pair_len > 3000\n","        ):\n","            self.history_memory.pop(0)\n","            self.history_memory.pop(0)\n","        self.history_memory.append(human_message)\n","        self.history_memory.append(ai_message)\n","\n","    def call(self, prompt: str, document: str) -> str:\n","        with get_openai_callback() as cb:\n","            response = self.llm(\n","                self.initial_history_memory\n","                + self.history_memory\n","                + [\n","                    HumanMessage(\n","                        content=f\"질문:\\n{prompt}\\n\\n ### 참고용 문서(질문과 관련 없으면 절대 참고하지 않기):\\n{document}\\n\"\n","                    )\n","                ]\n","            )\n","\n","        if self.verbose:\n","            print(cb)\n","\n","        response = response.content\n","        print(response)\n","\n","        self.append_limit_length(\n","            HumanMessage(content=prompt), AIMessage(content=response)\n","        )\n","        return response\n","\n","    def set_callbacks(self, callbacks):\n","        self.llm = ChatOpenAI(\n","            model=self.model,\n","            temperature=0.3,\n","            streaming=self.streaming,\n","            callbacks=callbacks,\n","        )\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1702426411225,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"ob-9nYRiimRI"},"outputs":[],"source":["# llmvdb/__init__.py\n","\n","class Llmvdb:\n","    def __init__(\n","        self,\n","        embedding=None,\n","        llm=None,\n","        verbose: bool = False,\n","        file_path=None,\n","        workspace: Optional[str] = None,\n","        threshold: float = 0.7,\n","        top_k: int = 3,\n","    ):\n","        self.embedding = embedding\n","        self.llm = llm\n","        self.verbose = verbose\n","        self.workspace = workspace\n","        self.file_path = file_path\n","        self.threshold = threshold\n","        self.top_k = top_k\n","\n","        self.db = InMemoryExactNNVectorDB[ToyDoc](workspace=self.workspace)\n","\n","    def custom_collate_fn(self, batch):\n","        texts = [item[\"text\"] for item in batch]\n","        questions = [item[\"question\"] for item in batch]\n","        ctx_ids = [item[\"ctx_id\"] for item in batch]\n","        tit_ids = [item[\"tit_id\"] for item in batch]\n","        batched_data = []\n","        for i in range(len(batch)):\n","            batched_data.append(\n","                {\n","                    \"text\": texts[i],\n","                    \"question\": questions[i],\n","                    \"ctx_id\": ctx_ids[i],\n","                    \"tit_id\": tit_ids[i],\n","                }\n","            )\n","        return batched_data\n","\n","    def initialize_db(self):\n","        dataset = CustomDataset(self.file_path)\n","        dataloader = DataLoader(\n","            dataset, batch_size=64, shuffle=False, collate_fn=self.custom_collate_fn\n","        )\n","        doc_list = []\n","\n","        for batch in tqdm(dataloader, desc=\"Processing dataset embedding\"):\n","            texts = [data[\"text\"] for data in batch if data[\"text\"].strip() != \"\"]\n","            context_embeddings = self.embedding.get_embedding(texts)\n","\n","            for j, data in enumerate(batch):\n","                if data[\"text\"].strip() != \"\":\n","                    doc_list.append(\n","                        ToyDoc(\n","                            text=data[\"text\"],\n","                            context_embedding=context_embeddings[j],\n","                            question=data[\"question\"],\n","                            tit_id=data[\"tit_id\"],\n","                            ctx_id=data[\"ctx_id\"],\n","                        )\n","                    )\n","\n","        self.db.index(inputs=DocList[ToyDoc](doc_list))\n","        self.db.persist()\n","\n","    def retrieve_document(self, prompt):\n","        query = ToyDoc(\n","            text=prompt, context_embedding=self.embedding.get_embedding(prompt)\n","        )\n","        search_parameters = {\"search_field\": \"context_embedding\"}\n","        results = self.db.search(\n","            inputs=DocList[ToyDoc]([query]),\n","            parameters=search_parameters,\n","            limit=self.top_k,\n","        )\n","\n","        input_document = \"\"\n","        over_threshold_indices = [\n","            idx for idx, value in enumerate(results[0].scores) if value > self.threshold\n","        ]\n","\n","        if self.verbose:\n","            # print(results[0].matches[0])\n","            # print(results[0].matches.ctx_id)\n","            print(results[0].text, results[0].scores)\n","            print(f\"threshold를 넘는 index : {over_threshold_indices}\")\n","\n","            # 만약 threshold 0.8을 넘는게 있고 그 개수가 k개보다 적다면 전부 retrieve\n","        if 1 <= len(over_threshold_indices) < self.top_k:\n","            for index in over_threshold_indices:  # top-k (k=3)\n","                input_document += (\n","                    \"#문서\" + str(index) + \"\\n\" + results[0].matches[index].text + \"\\n\"\n","                )\n","\n","        # 만약 threshold 0.8을 넘는게 있고 그 개수가 k개보다 많다면 top-k만 retrieve\n","        elif len(over_threshold_indices) >= self.top_k:\n","            for index in range(self.top_k):  # top-k (k=3)\n","                input_document += (\n","                    \"#문서\" + str(index) + \"\\n\" + results[0].matches[index].text + \"\\n\"\n","                )\n","\n","        # 만약 threshold 0.8을 넘는게 없다면 top-1만\n","        elif len(over_threshold_indices) == 0:\n","            input_document += \"#문서\\n\" + results[0].matches[0].text + \"\\n\"\n","\n","        if self.verbose:\n","            print(\"================아래 문서를 참고합니다================\")\n","            print(input_document)\n","            print(\"======================================================\")\n","\n","        return input_document\n","\n","    def generate_response(self, prompt):\n","        input_document = self.retrieve_document(prompt)\n","        completion = self.llm.call(prompt, input_document)\n","        return completion\n","\n","    def change_embedding(self, new_embedding):\n","        self.embedding = new_embedding\n","\n","    def evaluate_model(self, target_model):\n","        dataset = EvalCustomDataset(\"data/test.jsonl\")\n","        dataloader = DataLoader(\n","            dataset, batch_size=32, shuffle=False, collate_fn=self.custom_collate_fn\n","        )\n","        question_list = []\n","        for batch in tqdm(dataloader, desc=f\"embedding..{target_model}\"):\n","            question = [data[\"question\"] for data in batch]\n","            question_embedding = self.embedding.get_embedding(question)\n","            for idx, data in enumerate(batch):\n","                question_list.append(\n","                    ToyDoc(\n","                        question=data[\"question\"],\n","                        question_embedding=question_embedding[idx],\n","                        ctx_id=data[\"ctx_id\"],\n","                        tit_id=data[\"tit_id\"],\n","                    )\n","                )\n","        question_len = len(question_list)\n","        correct_counts = {\n","            1: 0,\n","            2: 0,\n","            3: 0,\n","            5: 0,\n","            7: 0,\n","            10: 0,\n","            20: 0,\n","            50: 0,\n","            \"model\": target_model,\n","            \"criteria\": \"ctx_id\",\n","        }\n","        correct_counts_tit_id = correct_counts.copy()\n","        correct_counts_tit_id[\"criteria\"] = \"tit_id\"\n","\n","        top_k_keys = sorted([k for k in correct_counts.keys() if isinstance(k, int)])\n","\n","        for q in tqdm(question_list, desc=f\"search..{target_model}\"):\n","            search_query = ToyDoc(\n","                question=q.question,\n","                context_embedding=q.question_embedding,\n","                ctx_id=q.ctx_id,\n","                tit_id=q.tit_id,\n","            )\n","            for top_k in top_k_keys:\n","                search_parameters = {\"search_field\": \"context_embedding\"}\n","                search_results = self.db.search(\n","                    inputs=DocList[ToyDoc]([search_query]),\n","                    parameters=search_parameters,\n","                    limit=top_k,\n","                )\n","\n","                ctx_id_matched = False\n","                for match in search_results[0].matches:\n","                    if match.ctx_id == search_query.ctx_id:\n","                        correct_counts[top_k] += 1\n","                        correct_counts_tit_id[top_k] += 1\n","                        ctx_id_matched = True\n","                        break\n","\n","                if not ctx_id_matched:\n","                    for match in search_results[0].matches:\n","                        if match.tit_id == search_query.tit_id:\n","                            correct_counts_tit_id[top_k] += 1\n","                            break\n","\n","        for key in top_k_keys:\n","            correct_counts[key] = correct_counts[key] / question_len\n","            correct_counts_tit_id[key] = correct_counts_tit_id[key] / question_len\n","\n","        return correct_counts, correct_counts_tit_id\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":527,"referenced_widgets":["21d668143c8c49d3842339d2ad99b66f","731d3860a34d4fd5a216fa47b02d3d40","36cd1c9a324145dda14b1f6345ac46eb","85c00036347942fa8d6a4e12fce14886","14ac1c9be1774097a3e91ffa804035eb","b42c597f41224e18a625e9588d5a1a22","7250271620f34f54a86a2fd9f1f068f3","2640b418efac401cbde41121689bbb09","7171a9c235cc424cad57f6ee499e7294","8555eb55192b4f78ac25d74649bdfcd7","21c7fd18f77540c8a15cdd36a7e06ce1","034e9c1d880c4cf5822fecd2f30aa276","a3fda504f2ad4b91a66fa12d38389b43","8a499e48e3a74d68b1ae39420d063e2d","ddfd6164d7bd40e38ae21b7a1c9bdc32","4c51ef69d8a14fbc976596554bcbe8da","a0a0ac165e3a4934b63d33084ffb71f8","92bebe28653043b3837fb9657bff4a08","d0a85a4a6d8447409d6fb360e0d0d26b","f07d1a85790d469481c69e6d656619c7","d141adf4341642b3a8683903857eeb1b","76d51fb42323410d8ce677c7622d09d7","c81b5894b0d14b5d9105dc81d650691c","138418abd0ca4c02805ac3b85140d41e","8b29ad1f0e464d4d825e6ed3c963c9d5","6f2ddaa9ed414b39ae4d72119c23c1b0","0fd320e03ad946208db585ee9402a545","851089897c8643738f4ae6cb2dc4aaeb","4dc01e7512174155ba672ac16f064e08","5550709554cd40eb928d0e25bb0dccd1","ad3b0f4a116c4c59aa5e1ed2bc7323fe","c4796b8c1d7e4abda694ee92572c5f5d","64a56652c4fd40e1a22214c52d5f8d11","76882c9bb68949bc93cda3df91acf152","879a4124124c43f2a4853c9eec7041f3","c49f5849ace44268954427de53e324e7","cc2c1b963d404dc6b2ea112ef4bb52de","f5f49331b1554a44a72978da6f6c2a26","b61037a6f4ae4e71bbee7ea291a697b0","f0bb0f93435a476a99b723473e890419","5640d09887984b2da00b2b67ac899e29","a079ccf11fb948d0985f409bcd212ee9","960bfa06cd8e47e5a3206bc59b51f14a","05a19294b6a14b13b9c5f3815acee5f5","218c68a0c602424999534c668946c1f8","620e2a45305c4fe59293e0c782b489c2","eda88b4d69f64fada03b727dedfc4a71","68244001b9e445f49a41ba638afb086c","25b065eab9d84e98add485207848dcf0","5abb7c211a6246fc8a647ae19dba08f0","71823c09c65c4475ada3ac634a899090","edf250a3fb9e46c5989b090b313e02ae","a9991f2da94b47bdbc191e9f8b384997","04951e492b134f70b29af8fc1fa16edd","d2cd8a3bd91d4d118b378ae2f1d3b7b6"]},"executionInfo":{"elapsed":100963,"status":"ok","timestamp":1702426536590,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"Fu5WyUdzmI48","outputId":"e683d9cf-1ab4-43c1-ef77-302ecd1b5ea9"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21d668143c8c49d3842339d2ad99b66f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"034e9c1d880c4cf5822fecd2f30aa276","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c81b5894b0d14b5d9105dc81d650691c","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76882c9bb68949bc93cda3df91acf152","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["=====cuda를 사용해서 임베딩합니다=====\n","=====cuda를 사용해서 임베딩합니다=====\n"]},{"name":"stderr","output_type":"stream","text":["WARNING - docarray - Index file does not exist: /content/drive/MyDrive/Colab Notebooks/슈팅스타/shootingstar_test/vectordb/museum_monologg_kobert_5ep/InMemoryExactNNIndexer[ToyDoc][ToyDocWithMatchesAndScores]/index.bin. Initializing empty InMemoryExactNNIndex.\n","WARNING:docarray:Index file does not exist: /content/drive/MyDrive/Colab Notebooks/슈팅스타/shootingstar_test/vectordb/museum_monologg_kobert_5ep/InMemoryExactNNIndexer[ToyDoc][ToyDocWithMatchesAndScores]/index.bin. Initializing empty InMemoryExactNNIndex.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"218c68a0c602424999534c668946c1f8","version_major":2,"version_minor":0},"text/plain":["Processing dataset embedding:   0%|          | 0/48 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["user: 마패에 대해서 알려줘\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:py.warnings:\u001b[1;33mUserWarning: Tensor shape mismatch. Reshaping tensor of shape (1, 768) to shape (768,)\u001b[0m \u001b[1;30m(raised from /usr/local/lib/python3.10/dist-packages/docarray/typing/tensor/abstract_tensor.py:202)\u001b[0m\n","\n"]},{"name":"stdout","output_type":"stream","text":["마패에 대해서 알려줘 [0.04271072521805763, 0.04242512956261635, 0.04232857748866081, 0.04229998588562012, 0.04228636622428894]\n","threshold를 넘는 index : []\n","================아래 문서를 참고합니다================\n","#문서\n","자치통감사정전훈의\n","“훈의만큼 상세하고 정밀한 책은 세상에 없을 것이다. 나는 우리나라의 훈의가 가장 우수하다고 생각한다.”\n","\n","======================================================\n","참고할 수 있는 문서가 없습니다. 혹시 마패가 어떤 것인지에 대해 더 자세한 정보를 알려주실 수 있나요?\n","AI:  참고할 수 있는 문서가 없습니다. 혹시 마패가 어떤 것인지에 대해 더 자세한 정보를 알려주실 수\n","있나요?\n","user: exit\n"]}],"source":["# main.py\n","class CLIHandler(BaseCallbackHandler):\n","    def __init__(self):\n","        self.text=''\n","\n","    def on_llm_new_token(self, token:str, **kwargs) -> None:\n","        self.text += token\n","\n","def main(\n","    data_file_path: str,\n","    workspace: str,\n","    model_path: str,\n","    model_name: str='klue/bert-base',\n","    is_dpr: bool = False,\n","    is_first: bool = False,\n","):\n","    cli_handler = CLIHandler()\n","\n","    if is_dpr:\n","        embedding = DPRTextEmbedding(\"passage\", model_path, model_name)\n","        question_embedding = DPRTextEmbedding(\"question\", model_path, model_name)\n","    else:\n","        embedding = HuggingFaceEmbedding(model_name)\n","\n","    llm = LangChain(callbacks=[cli_handler])\n","\n","    llmvdb = Llmvdb(\n","        embedding,\n","        llm,\n","        file_path=data_file_path,\n","        workspace=workspace,\n","        verbose=True,  # False로 설정시 터미널에 정보 출력 안됨\n","        threshold=0.1,\n","        top_k=5,\n","        )\n","    if is_first:\n","        llmvdb.initialize_db()  # vectordb저장, 처음에 한번만 실행\n","\n","        # is_dpr = True 이면 question embedding으로 변경\n","    if is_dpr:\n","        llmvdb.change_embedding(question_embedding)\n","\n","    while True:\n","        user_input = input('user: ')\n","        if user_input.lower() == 'exit':\n","            break\n","        try:\n","            response = llmvdb.generate_response(user_input)\n","            wrapped_response = textwrap.fill(response, width=55)\n","            print('AI: ', wrapped_response)\n","        except Exception as e:\n","            print(f'응답 생성중 오류 발생: {e}')\n","\n","if __name__ == \"__main__\":\n","    main(\n","        # 질문-문서 데이터셋 경로\n","        data_file_path='data/train.jsonl',\n","\n","        # 임베딩된 데이터가 저장되는(되어있는) 경로\n","        workspace='vectordb/museum_skt_kobert',\n","\n","        #학습된 dpr모델(.pth파일)의 경로\n","        model_path='data/museum_skt_kobert.pth',\n","\n","        # 기반이 되는 모델\n","        model_name='skt/kobert-base-v1',\n","\n","        # DPR 모델 사용 여부\n","        is_dpr=True,\n","\n","        # 처음 실행 여부\n","        is_first=False,\n","        # 주의 : 이 값을 True로 하는 경우 = 모델을 바꾸거나, workspace를 변경했을때 True\n","        # 처음 폴더를 받은 상태에서 돌려보기만 할땐 False로 둬도 됨!\n","    )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1702426411225,"user":{"displayName":"최우성","userId":"12667497140834652014"},"user_tz":-540},"id":"nigLkFoY0i8q"},"outputs":[],"source":["# eval.py\n","!mkdir -p eval\n","\n","\n","\n","def eval_model(\n","    model_paths: list,\n","    workspaces: list,\n","    model_names: list,\n","    is_first: bool = False,\n","):\n","    if not is_first:\n","        if os.path.exists(\"eval/model_performance.csv\"):\n","            df = pd.read_csv(\"eval/model_performance.csv\")\n","            existed_models = set(\"vectordb/\" + df[\"model\"])\n","\n","    model_performance = []\n","    for model_path, workspace, model_name in zip(model_paths, workspaces, model_names):\n","        target_model = workspace.split(\"/\")[-1]\n","        if not is_first and workspace in existed_models:\n","            print(f\"{target_model}의 평가 결과는 이미 저장되어 있으므로 넘어갑니다.\")\n","            continue\n","        print(model_path, workspace)\n","        if model_path:\n","            embedding = DPRTextEmbedding(\"question\", model_path, model_name)\n","        else:\n","            print(\"====== klue/bert-base =====\")\n","            embedding = HuggingFaceEmbedding(model_name)\n","        vdb = Llmvdb(\n","            embedding,\n","            workspace=workspace,\n","            verbose=True,\n","        )\n","\n","        accuracy, accuracy_tit = vdb.evaluate_model(target_model)\n","        for accuracy_dict in [accuracy, accuracy_tit]:\n","            new_accuracy_dict = {\n","                f\"Top_{k}\": v for k, v in accuracy_dict.items() if isinstance(k, int)\n","            }\n","            for k in [\"model\", \"question_len\", \"criteria\"]:\n","                if k in accuracy_dict:\n","                    new_accuracy_dict[k] = accuracy_dict[k]\n","            model_performance.append(new_accuracy_dict)\n","\n","    df = pd.DataFrame(model_performance)\n","    if is_first:\n","        df.to_csv(f\"eval/model_performance.csv\", index=False, encoding=\"utf-8\")\n","    elif not df.empty:\n","        df.to_csv(\n","            f\"eval/model_performance.csv\",\n","            mode=\"a\",\n","            index=False,\n","            header=False,\n","            encoding=\"utf-8\",\n","        )\n","    return df\n","\n","\n","class GraphMaker:\n","    def __init__(self, df: pd.DataFrame):\n","        # df = df.drop(columns=\"Top_50\")\n","        self.df = df\n","        self.top_k_labels = [label for label in df.columns if label.startswith(\"Top_\")]\n","        self.x_values = [int(label.split(\"_\")[1]) for label in self.top_k_labels]\n","        self.model_colors = {\n","            model: color\n","            for model, color in zip(\n","                df[\"model\"].unique(), plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n","            )\n","        }\n","\n","    def make_graph(self, criteria=None):\n","        plt.figure(figsize=(12, 8))\n","\n","        if criteria:\n","            self.plot_criteria(criteria, linestyle=\"solid\")\n","        else:\n","            self.plot_criteria(\"ctx_id\", linestyle=\"solid\")\n","            self.plot_criteria(\"tit_id\", linestyle=\"dotted\")\n","        plt.title(\n","            f\"Model-wise Top_k Accuracy ({'ctx_id & tit_id ' if not criteria else criteria})\"\n","        )\n","        self.finalize_plot()\n","\n","    def plot_criteria(self, criteria, linestyle):\n","        for model in self.df[\"model\"].unique():\n","            subset = self.df[\n","                (self.df[\"model\"] == model) & (self.df[\"criteria\"] == criteria)\n","            ]\n","            y_values = subset[self.top_k_labels].iloc[0]\n","            plt.plot(\n","                self.x_values,\n","                y_values,\n","                label=f\"{model} ({criteria})\",\n","                linestyle=linestyle,\n","                color=self.model_colors[model],\n","            )\n","\n","    def finalize_plot(self):\n","        plt.xlabel(\"Top_k\")\n","        plt.ylabel(\"Accuracy\")\n","        plt.legend()\n","        plt.xticks(self.x_values, self.top_k_labels, rotation=45)\n","        plt.grid(True)\n","        plt.show()\n","\n","\n","if __name__ == \"__main__\":\n","    # 평가할 모델의 경로를 순서대로 적어줍니다 (workspace와 순서가 같아야함)\n","    # \"\"은 klue/bert-base 모델을 적용합니다 (dpr X)\n","    model_paths = [\n","        \"\",\n","        \"data/museum_5epochs.pth\",\n","        \"data/merged_pn_5ep.pth\",\n","        \"data/museum_kdpr.pth\",  # aihub_5epochs\n","        \"data/museum_monologg_kobert.pth\",  # 5ep\n","    ]\n","\n","    # 해당 모델로 임베딩한 index.bin이 있는 경로를 지정해줍니다.\n","    # 여기서 '/' 다음 부분이 csv파일에 모델이름으로 기록되게 됩니다.\n","    workspaces = [\n","        \"vectordb/bert-base\",\n","        \"vectordb/museum_5epochs\",\n","        \"vectordb/merged_pn_5ep\",\n","        \"vectordb/aihub_5epochs\",\n","        \"vectordb/museum_monologg_kobert_5ep\",\n","    ]\n","\n","    # 기반 모델 이름(기본: klue/bert-base)\n","    model_names = [\n","        \"klue/bert-base\",\n","        \"klue/bert-base\",\n","        \"klue/bert-base\",\n","        \"klue/bert-base\",\n","        \"monologg/kobert\",\n","    ]\n","    # eval/model_performance.csv 파일이 있다면 False로, False이면 이전에 했던 평가는 저장된값을 사용함\n","    is_first = False\n","\n","    df = eval_model(model_paths, workspaces, model_names, is_first)\n","\n","    df = pd.read_csv(f\"eval/model_performance.csv\")\n","    print(df[df[\"criteria\"] == \"ctx_id\"])\n","    print(df[df[\"criteria\"] == \"tit_id\"])\n","    graph_maker = GraphMaker(df)\n","    graph_maker.make_graph(\"ctx_id\")\n","    graph_maker.make_graph(\"tit_id\")\n","    graph_maker.make_graph()\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"034e9c1d880c4cf5822fecd2f30aa276":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3fda504f2ad4b91a66fa12d38389b43","IPY_MODEL_8a499e48e3a74d68b1ae39420d063e2d","IPY_MODEL_ddfd6164d7bd40e38ae21b7a1c9bdc32"],"layout":"IPY_MODEL_4c51ef69d8a14fbc976596554bcbe8da"}},"04951e492b134f70b29af8fc1fa16edd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05a19294b6a14b13b9c5f3815acee5f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fd320e03ad946208db585ee9402a545":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138418abd0ca4c02805ac3b85140d41e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_851089897c8643738f4ae6cb2dc4aaeb","placeholder":"​","style":"IPY_MODEL_4dc01e7512174155ba672ac16f064e08","value":"vocab.txt: 100%"}},"14ac1c9be1774097a3e91ffa804035eb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"218c68a0c602424999534c668946c1f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_620e2a45305c4fe59293e0c782b489c2","IPY_MODEL_eda88b4d69f64fada03b727dedfc4a71","IPY_MODEL_68244001b9e445f49a41ba638afb086c"],"layout":"IPY_MODEL_25b065eab9d84e98add485207848dcf0"}},"21c7fd18f77540c8a15cdd36a7e06ce1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21d668143c8c49d3842339d2ad99b66f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_731d3860a34d4fd5a216fa47b02d3d40","IPY_MODEL_36cd1c9a324145dda14b1f6345ac46eb","IPY_MODEL_85c00036347942fa8d6a4e12fce14886"],"layout":"IPY_MODEL_14ac1c9be1774097a3e91ffa804035eb"}},"25b065eab9d84e98add485207848dcf0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2640b418efac401cbde41121689bbb09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36cd1c9a324145dda14b1f6345ac46eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2640b418efac401cbde41121689bbb09","max":51,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7171a9c235cc424cad57f6ee499e7294","value":51}},"4c51ef69d8a14fbc976596554bcbe8da":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dc01e7512174155ba672ac16f064e08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5550709554cd40eb928d0e25bb0dccd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5640d09887984b2da00b2b67ac899e29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5abb7c211a6246fc8a647ae19dba08f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"620e2a45305c4fe59293e0c782b489c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5abb7c211a6246fc8a647ae19dba08f0","placeholder":"​","style":"IPY_MODEL_71823c09c65c4475ada3ac634a899090","value":"Processing dataset embedding: 100%"}},"64a56652c4fd40e1a22214c52d5f8d11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68244001b9e445f49a41ba638afb086c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04951e492b134f70b29af8fc1fa16edd","placeholder":"​","style":"IPY_MODEL_d2cd8a3bd91d4d118b378ae2f1d3b7b6","value":" 48/48 [00:43&lt;00:00,  1.31it/s]"}},"6f2ddaa9ed414b39ae4d72119c23c1b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4796b8c1d7e4abda694ee92572c5f5d","placeholder":"​","style":"IPY_MODEL_64a56652c4fd40e1a22214c52d5f8d11","value":" 77.8k/77.8k [00:00&lt;00:00, 1.11MB/s]"}},"7171a9c235cc424cad57f6ee499e7294":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71823c09c65c4475ada3ac634a899090":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7250271620f34f54a86a2fd9f1f068f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"731d3860a34d4fd5a216fa47b02d3d40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b42c597f41224e18a625e9588d5a1a22","placeholder":"​","style":"IPY_MODEL_7250271620f34f54a86a2fd9f1f068f3","value":"tokenizer_config.json: 100%"}},"76882c9bb68949bc93cda3df91acf152":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_879a4124124c43f2a4853c9eec7041f3","IPY_MODEL_c49f5849ace44268954427de53e324e7","IPY_MODEL_cc2c1b963d404dc6b2ea112ef4bb52de"],"layout":"IPY_MODEL_f5f49331b1554a44a72978da6f6c2a26"}},"76d51fb42323410d8ce677c7622d09d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"851089897c8643738f4ae6cb2dc4aaeb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8555eb55192b4f78ac25d74649bdfcd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c00036347942fa8d6a4e12fce14886":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8555eb55192b4f78ac25d74649bdfcd7","placeholder":"​","style":"IPY_MODEL_21c7fd18f77540c8a15cdd36a7e06ce1","value":" 51.0/51.0 [00:00&lt;00:00, 1.72kB/s]"}},"879a4124124c43f2a4853c9eec7041f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b61037a6f4ae4e71bbee7ea291a697b0","placeholder":"​","style":"IPY_MODEL_f0bb0f93435a476a99b723473e890419","value":"model.safetensors: 100%"}},"8a499e48e3a74d68b1ae39420d063e2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0a85a4a6d8447409d6fb360e0d0d26b","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f07d1a85790d469481c69e6d656619c7","value":426}},"8b29ad1f0e464d4d825e6ed3c963c9d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5550709554cd40eb928d0e25bb0dccd1","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad3b0f4a116c4c59aa5e1ed2bc7323fe","value":77779}},"92bebe28653043b3837fb9657bff4a08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"960bfa06cd8e47e5a3206bc59b51f14a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a079ccf11fb948d0985f409bcd212ee9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0a0ac165e3a4934b63d33084ffb71f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3fda504f2ad4b91a66fa12d38389b43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0a0ac165e3a4934b63d33084ffb71f8","placeholder":"​","style":"IPY_MODEL_92bebe28653043b3837fb9657bff4a08","value":"config.json: 100%"}},"a9991f2da94b47bdbc191e9f8b384997":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad3b0f4a116c4c59aa5e1ed2bc7323fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b42c597f41224e18a625e9588d5a1a22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b61037a6f4ae4e71bbee7ea291a697b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4796b8c1d7e4abda694ee92572c5f5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c49f5849ace44268954427de53e324e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5640d09887984b2da00b2b67ac899e29","max":368769812,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a079ccf11fb948d0985f409bcd212ee9","value":368769812}},"c81b5894b0d14b5d9105dc81d650691c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_138418abd0ca4c02805ac3b85140d41e","IPY_MODEL_8b29ad1f0e464d4d825e6ed3c963c9d5","IPY_MODEL_6f2ddaa9ed414b39ae4d72119c23c1b0"],"layout":"IPY_MODEL_0fd320e03ad946208db585ee9402a545"}},"cc2c1b963d404dc6b2ea112ef4bb52de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_960bfa06cd8e47e5a3206bc59b51f14a","placeholder":"​","style":"IPY_MODEL_05a19294b6a14b13b9c5f3815acee5f5","value":" 369M/369M [00:02&lt;00:00, 128MB/s]"}},"d0a85a4a6d8447409d6fb360e0d0d26b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d141adf4341642b3a8683903857eeb1b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2cd8a3bd91d4d118b378ae2f1d3b7b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ddfd6164d7bd40e38ae21b7a1c9bdc32":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d141adf4341642b3a8683903857eeb1b","placeholder":"​","style":"IPY_MODEL_76d51fb42323410d8ce677c7622d09d7","value":" 426/426 [00:00&lt;00:00, 7.64kB/s]"}},"eda88b4d69f64fada03b727dedfc4a71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_edf250a3fb9e46c5989b090b313e02ae","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a9991f2da94b47bdbc191e9f8b384997","value":48}},"edf250a3fb9e46c5989b090b313e02ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f07d1a85790d469481c69e6d656619c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0bb0f93435a476a99b723473e890419":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5f49331b1554a44a72978da6f6c2a26":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
